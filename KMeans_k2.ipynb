{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22d3c367-ed77-44a0-9169-9ab74d6e38ff",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529b93ab-1c4c-4544-9643-6aa667125e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "import pandas_ta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a38a9a6-c1d0-440a-bb35-2985d7222d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list with the given ticker symbols\n",
    "klci_stocks = [\n",
    "    '5681.KL', '3182.KL', '1066.KL', '5285.KL', '5296.KL', '1295.KL',\n",
    "    '1082.KL', '5183.KL', '7084.KL', '1155.KL', '5819.KL', '1015.KL',\n",
    "    '4863.KL', '5225.KL', '4715.KL', '5347.KL', '1961.KL', '1023.KL',\n",
    "    '6888.KL', '4707.KL', '4065.KL', '6947.KL', '6012.KL', '2445.KL',\n",
    "    '3816.KL', '4197.KL', '4677.KL', '6033.KL', '6742.KL', '8869.KL'\n",
    "]\n",
    "\n",
    "# Display the list\n",
    "print(klci_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d707635d-f389-40a3-88df-236418affad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "end_date = '2024-03-31'\n",
    "\n",
    "start_date = '2022-01-01'\n",
    "\n",
    "df = yf.download(tickers=klci_stocks,\n",
    "                 start=start_date,\n",
    "                 end=end_date).stack()\n",
    "\n",
    "#set date and ticker as index\n",
    "df.index.names = ['date', 'ticker']\n",
    "\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e886f9a-172b-414b-9782-fa8d42a6d777",
   "metadata": {},
   "source": [
    "## Calculate Technical Indicator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d52ac1-9b9d-4a59-b077-ab63ecb1c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas-ta\n",
    "import pandas_ta as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5dab2f-e176-424c-8de7-09a3b240949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['garman_klass_vol'] = ((np.log(df['high'])-np.log(df['low']))**2)/2-(2*np.log(2)-1)*((np.log(df['adj close'])-np.log(df['open']))**2)\n",
    "\n",
    "##################can try adjust length\n",
    "df['rsi'] = df.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.rsi(close=x, length=20))\n",
    "\n",
    "df['bb_low'] = df.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=20).iloc[:,0])\n",
    "                                                          \n",
    "df['bb_mid'] = df.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=20).iloc[:,1])\n",
    "                                                          \n",
    "df['bb_high'] = df.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=20).iloc[:,2])\n",
    "\n",
    "def compute_atr(stock_data):\n",
    "    atr = pandas_ta.atr(high=stock_data['high'],\n",
    "                        low=stock_data['low'],\n",
    "                        close=stock_data['close'],\n",
    "                        length=14)\n",
    "    \n",
    "    return atr.sub(atr.mean()).div(atr.std())\n",
    "\n",
    "df['atr'] = df.groupby(level=1, group_keys=False).apply(compute_atr)\n",
    "\n",
    "def compute_macd(close):\n",
    "    macd = ta.macd(close=close, length=20).iloc[:,0]\n",
    "    return macd.sub(macd.mean()).div(macd.std())\n",
    "\n",
    "df['macd'] = df.groupby(level=1, group_keys=False)['adj close'].apply(compute_macd)\n",
    "\n",
    "df['dollar_volume'] = (df['adj close']*df['volume'])/1e6\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab4d721-dd52-487a-a619-1a46d4c15dac",
   "metadata": {},
   "source": [
    "## Aggregate to monthly level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9e7926-6880-44a2-b883-42c085af66c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_cols = [c for c in df.columns.unique(0) if c not in ['dollar_volume', 'volume', 'open',\n",
    "                                                          'high', 'low', 'close','daily return']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4478b1-a58e-4310-ab66-3c6389aa993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To reduce training time and experiment with features and strategies\n",
    "#convert the business-daily data to month-end frequency.\n",
    "\n",
    "monthdata = df.unstack()[last_cols].resample('M').last().stack('ticker').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19135a3-2bb0-44c7-ab59-e57c95c6d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cb5624-210f-4fd6-91d4-61fb36afa4bc",
   "metadata": {},
   "source": [
    "## Monthly Returns for Different Time Horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc0bd5-3d16-4a27-93a9-a33ae700a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_returns(df):\n",
    "\n",
    "    outlier_cutoff = 0.005\n",
    "\n",
    "    lags = [1,3,6,9]\n",
    "\n",
    "    for lag in lags:\n",
    "\n",
    "        df[f'return_{lag}m'] = (df['adj close']\n",
    "                              .pct_change(lag)\n",
    "                              .pipe(lambda x: x.clip(lower=x.quantile(outlier_cutoff),\n",
    "                                                     upper=x.quantile(1-outlier_cutoff)))\n",
    "                              .add(1)\n",
    "                              .pow(1/lag)\n",
    "                              .sub(1))\n",
    "    return df\n",
    "    \n",
    "    \n",
    "monthdata = monthdata.groupby(level=1, group_keys=False).apply(calculate_returns).dropna()\n",
    "monthdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef53be50-b199-4022-88ad-c4f7f1b5984b",
   "metadata": {},
   "source": [
    "## FAMA-FRENCH FIVE FACTOR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7fb365-4ad3-48c2-9c17-80aba65b1c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data = web.DataReader('Emerging_5_Factors',\n",
    "                               'famafrench',\n",
    "                               start='2022')[0].drop('RF', axis=1)\n",
    "\n",
    "factor_data.index = factor_data.index.to_timestamp()\n",
    "\n",
    "factor_data = factor_data.resample('M').last().div(100)\n",
    "\n",
    "factor_data.index.name = 'date'\n",
    "\n",
    "factor_data = factor_data.join(monthdata['return_1m'])\n",
    "\n",
    "factor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2a3970-eb87-4a55-8c9a-7888aaff3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate rolling factor betas\n",
    "\n",
    "betas = (factor_data.groupby(level=1,\n",
    "                            group_keys=False)\n",
    "         .apply(lambda x: RollingOLS(endog=x['return_1m'], \n",
    "                                     exog=sm.add_constant(x.drop('return_1m', axis=1)),\n",
    "                                     window=min(6, x.shape[0]),\n",
    "                                     min_nobs=len(x.columns))\n",
    "         .fit(params_only=True)\n",
    "         .params\n",
    "         .drop('const', axis=1)))\n",
    "\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4fda3c-9b8f-46d4-91db-b37243bd06e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']\n",
    "\n",
    "proc_data = (monthdata.join(betas.groupby('ticker').shift()))\n",
    "\n",
    "proc_data.loc[:, factors] = proc_data.groupby('ticker', group_keys=False)[factors].apply(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "proc_data = proc_data.drop('adj close', axis=1)\n",
    "\n",
    "proc_data = proc_data.dropna()\n",
    "\n",
    "proc_data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f072ee2-c190-4f48-91ba-a4a271ba4038",
   "metadata": {},
   "source": [
    "# K-Means Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2acb914-0121-4eeb-bf31-817eef13d127",
   "metadata": {},
   "source": [
    "## Parameter selection based on Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c972b34c-b293-4808-82b8-baebbe766d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "Sum_of_squared_distances = []\n",
    "K = range(1,10)\n",
    "for num_clusters in K :\n",
    " kmeans = KMeans(n_clusters=num_clusters)\n",
    " kmeans.fit(proc_data)\n",
    " Sum_of_squared_distances.append(kmeans.inertia_)\n",
    "plt.plot(K,Sum_of_squared_distances,'bx-')\n",
    "plt.xlabel('Values of K') \n",
    "plt.ylabel('Sum of squared distances/Inertia') \n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61107ecb-ae6b-40b4-a82f-84613288b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette_avg = []\n",
    "K = range(2,10)\n",
    "for num_clusters in K :\n",
    "    kmeans = KMeans(n_clusters=num_clusters)\n",
    "    kmeans.fit(proc_data)\n",
    "    cluster_labels = kmeans.labels_\n",
    "    silhouette_avg.append(silhouette_score(proc_data,cluster_labels))\n",
    "    \n",
    "plt.plot(K,silhouette_avg,'bx-')\n",
    "plt.xlabel('Values of K') \n",
    "plt.ylabel('Sum of squared distances/Inertia') \n",
    "plt.title('Silhoutte score For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5e73fb-8a26-430f-b738-4c19560086fb",
   "metadata": {},
   "source": [
    "As indicated by both elbow method and also the silhoutte scores (0.25-0.5 generally means a fair clustering), the suitable number of clusters is 3, but number of cluster 2 obtained a similar silhouette score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f23373-aed5-4a91-88d4-84abb7837ffd",
   "metadata": {},
   "source": [
    "Centroids is predefined by strategy trusting the stocks with high momentum will continue perform at the next month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d757eba3-7270-4164-97ea-22b537fbca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_rsi_values = [25,75]\n",
    "\n",
    "initial_centroids = np.zeros((len(target_rsi_values), 16))\n",
    "\n",
    "initial_centroids[:, 1] = target_rsi_values\n",
    "\n",
    "initial_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc5c468-4207-4371-9629-82ff48c16f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "def get_clusters(df):\n",
    "    df['cluster'] = KMeans(n_clusters=2,\n",
    "                            random_state=42,\n",
    "                            init=initial_centroids).fit(df).labels_\n",
    "    \n",
    "    return df\n",
    "\n",
    "KM_random_data = proc_data.dropna().groupby('date', group_keys=False).apply(get_clusters)\n",
    "\n",
    "KM_random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b628be8-edad-496d-a63c-eb1407de63cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(data):\n",
    "\n",
    "    cluster_0 = data[data['cluster']==0]\n",
    "    cluster_1 = data[data['cluster']==1]\n",
    "\n",
    "\n",
    "    plt.scatter(cluster_0.iloc[:,5] , cluster_0.iloc[:,1] , color = 'red', label='cluster 0')\n",
    "    plt.scatter(cluster_1.iloc[:,5] , cluster_1.iloc[:,1] , color = 'green', label='cluster 1')\n",
    "\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a0448-e363-4d7c-a708-bb4bdbbcb4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "monthly_silhouette = []\n",
    "\n",
    "for i in KM_random_data.index.get_level_values('date').unique().tolist():\n",
    "    \n",
    "    g = KM_random_data.xs(i, level=0)\n",
    "    \n",
    "    plt.title(f'Date {i}')\n",
    "    \n",
    "    plot_clusters(g)\n",
    "    \n",
    "    silhouette = silhouette_score(g,g['cluster'])\n",
    "\n",
    "    monthly_silhouette.append(silhouette)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8217e8e3-6c82-453e-8966-cb2f2e8f57ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean \n",
    "\n",
    "\n",
    "print('the mean silhouette score across months :',mean(monthly_silhouette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3abbbb-f552-4a08-a430-bcbd63722fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe is filtered by selecting only cluster with centroid of higher RSI value\n",
    "filtered_df = KM_random_data[KM_random_data['cluster']==1].copy()\n",
    "\n",
    "filtered_df = filtered_df.reset_index(level=1)\n",
    "\n",
    "filtered_df.index = filtered_df.index+pd.DateOffset(1)\n",
    "\n",
    "filtered_df = filtered_df.reset_index().set_index(['date', 'ticker'])\n",
    "\n",
    "dates = filtered_df.index.get_level_values('date').unique().tolist()\n",
    "\n",
    "fixed_dates = {}\n",
    "\n",
    "for d in dates:\n",
    "    \n",
    "    fixed_dates[d.strftime('%Y-%m-%d')] = filtered_df.xs(d, level=0).index.tolist()\n",
    "    \n",
    "fixed_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69431e23-2f5e-4395-b52a-1e9f7335971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To obtain the frequency of each stock invested\n",
    "stock_frequency = filtered_df.index.get_level_values('ticker').value_counts()\n",
    "\n",
    "print(stock_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f96439-ffec-4671-9008-c55514cd8675",
   "metadata": {},
   "source": [
    "### Portfolio Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b10e4-b46f-4a47-b6f8-03bdaa81788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPortfolioOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4055875-01e9-4881-bde1-74ade17c9236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "\n",
    "# define the function for optimization of weightage assigned\n",
    "\n",
    "def optimize_weights(prices, lower_bound=0):\n",
    "    \n",
    "    returns = expected_returns.mean_historical_return(prices=prices,\n",
    "                                                      frequency=252)\n",
    "    \n",
    "    cov = risk_models.sample_cov(prices=prices,\n",
    "                                 frequency=252)\n",
    "    \n",
    "    ef = EfficientFrontier(expected_returns=returns,\n",
    "                           cov_matrix=cov,\n",
    "                           weight_bounds=(lower_bound, .1),\n",
    "                           solver='SCS')\n",
    "    \n",
    "    weights = ef.max_sharpe()\n",
    "    \n",
    "    return ef.clean_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cd086e-1ff3-494c-917c-32d04efff31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#daily data is used in optimization\n",
    "#the daily data of selected stocks is obtained starts from 1 year prior 2022\n",
    "stocks = KM_random_data.index.get_level_values('ticker').unique().tolist()\n",
    "\n",
    "new_df = yf.download(tickers=stocks,\n",
    "                     start=KM_random_data.index.get_level_values('date').unique()[0]-pd.DateOffset(months=12),\n",
    "                     end=KM_random_data.index.get_level_values('date').unique()[-1])\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b109fc5a-0dda-4e4b-920d-5bb0d4917af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_dataframe = np.log(new_df['Adj Close']).diff()\n",
    "\n",
    "portfolio_df = pd.DataFrame()\n",
    "\n",
    "stock_weights=pd.DataFrame()\n",
    "\n",
    "for start_date in fixed_dates.keys():\n",
    "\n",
    "    try :\n",
    "        end_date = (pd.to_datetime(start_date)+pd.offsets.MonthEnd(0)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        cols = fixed_dates[start_date]\n",
    "    \n",
    "        #optimization requires 1year data\n",
    "        optimization_start_date = (pd.to_datetime(start_date)-pd.DateOffset(months=12)).strftime('%Y-%m-%d')\n",
    "            \n",
    "        optimization_end_date = (pd.to_datetime(start_date)-pd.DateOffset(days=1)).strftime('%Y-%m-%d')\n",
    "    \n",
    "        optimization_df = new_df[optimization_start_date:optimization_end_date]['Adj Close'][cols]\n",
    "\n",
    "        success = False\n",
    "\n",
    "        try:\n",
    "            #optimize and find the weights for the stocks of that month\n",
    "            weights = optimize_weights(prices=optimization_df,\n",
    "                                   lower_bound = round(1/(len(optimization_df.columns)*2),3))\n",
    "        \n",
    "            weights = pd.DataFrame(weights, index=pd.Series(0))\n",
    "\n",
    "            success = True\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            #Assign equal weight to every stocks if optimization failed\n",
    "            print(f'Max Sharpe Optimization failed for {start_date}, continuing with equal weight')\n",
    "\n",
    "        if success == False:\n",
    "            weight = pd.DataFrame([1/len(optimization_df.columns) for i in range(len(optimization_df.columns))],\n",
    "                                    index=optimization_df.columns.tolist(),\n",
    "                                    columns=pd.Series(0)).T\n",
    "            \n",
    "        #multiply the weight with the return for everyday\n",
    "        #to calc the daily portfolio return\n",
    "        temp_df = returns_dataframe[start_date:end_date]\n",
    "\n",
    "    \n",
    "        temp_df = temp_df.stack().to_frame('return').reset_index(level=0).merge(weights.stack().to_frame('weight').reset_index(level=0,drop=True),\n",
    "                                                                  left_index=True,\n",
    "                                                                  right_index=True).reset_index().set_index(['Date','Ticker']).unstack().stack()\n",
    "\n",
    "    \n",
    "        \n",
    "        temp_df['weighted_return'] = temp_df['return']*temp_df['weight']\n",
    "\n",
    "        stock_weights = pd.concat([stock_weights, temp_df])\n",
    "    \n",
    "        temp_df = temp_df.groupby(level=0)['weighted_return'].sum().to_frame('Strategy Return')\n",
    "    \n",
    "        portfolio_df = pd.concat([portfolio_df, temp_df],axis=0)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "portfolio_df = portfolio_df.drop_duplicates()\n",
    "\n",
    "portfolio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b2813-1312-4c67-ba23-7ecc108fa4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to visualize the daily strategy return\n",
    "portfolio_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfd26c9-3f96-4dc4-9b11-77800f61cf5d",
   "metadata": {},
   "source": [
    "## Visualize Cumulative Portfolio Returns and Compare to KLCI Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cec8e0-41ec-444e-8379-5fab98cdf538",
   "metadata": {},
   "outputs": [],
   "source": [
    "klci = yf.download(tickers='^KLSE',\n",
    "                   start = '2022-01-01',\n",
    "                   end=dt.date.today())\n",
    "klci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72133da9-a6dd-4cf2-8852-b7a082c5f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the return by buying the overall KLCI index and holding it over the investment period\n",
    "klci_ret = np.log(klci[['Adj Close']]).diff().dropna().rename({'Adj Close':'KLCI Buy&Hold'},axis=1)\n",
    "\n",
    "klci_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3690ecf-b2df-4eb2-9972-1db8923b4447",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_df = portfolio_df.merge(klci_ret,\n",
    "                                  left_index=True,\n",
    "                                  right_index=True)\n",
    "\n",
    "portfolio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68f6a99-39e3-426f-9e12-245797cc2bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "portfolio_cumulative_return = np.exp(np.log1p(portfolio_df).cumsum())-1\n",
    "\n",
    "portfolio_cumulative_return[:'2024-03-29'].plot(figsize=(16,6))\n",
    "\n",
    "plt.title('Unsupervised Learning Trading Strategy Returns Over Time')\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1))\n",
    "\n",
    "plt.ylabel('Return')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526ab4a7-d9eb-4d60-b04e-80c5d9366e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
